<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <link href='MainpageCss.css' rel='stylesheet'>
    <meta charset="utf-8">
    <title>A.I M.L & D.L</title>
  </head>
  <body>
    <header>
      <div class="wrapper">
        <nav>
          <ul>
            <li><a href="MainPage.html">HOME</a></li>
            <li><a>Artificial Inteligence</a>
              <ul>
                <li><a href="About_AI.html">About</a></li>
                <li><a href="History_AI.html">History</a></li>
                <li><a href="Examples_AI.html">Examples</a></li>
              </ul>
            </li>
            <li><a>Machine Learning</a>
              <ul>
                <li><a href="About_ML.html">About</a></li>
                <li><a href="History_ML.html">History</a></li>
                <li><a href="Examples_ML.html">Examples</a></li>
              </ul>
            </li>
            <li><a>Deep Learning</a>
              <ul>
                <li><a href="About_DL.html">About</a></li>
                <li><a href="History_DL.html">History</a></li>
                <li><a href="Examples_DL.html">Examples</a></li>
              </ul>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <h1>Deep Learning</h1>
    <hr>
    <h2>Automatic speech recognition</h2>
    <p>Large-Scale automatic speech recognizing is the first and most convincing successful case of deep learning. LSTM RNNs can learn "Very Deep Learning" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.</p>
    <p>The initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991. </p>
    <h2>Image Recognition</h2>
    <p>A common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.</p>
    <p>Deep learning-based image recognition has become "superhuman", producing more accurate results than human contestants. This first occurred in 2011.</p>
    <p>Deep learning-trained vehicles now interpret 360Â° camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.</p>
    <h2>Visual Art Processing</h2>
    <p>Closely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of a) identifying the style period of a given painting, b) "capturing" the style of a given painting and applying it in a visually pleasing manner to an arbitrary photograph, and c) generating striking imagery based on random visual input fields.</p>
    <h2>Natural Language Processing</h2>
    <p>Neural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.</p>
    <p>Other key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input
    layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing,sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, Text classification and others.</p>
    <p>Recent developments generalize word embedding to sentence embedding.Google Translate (GT) uses a large end-to-end long short-term memory network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system "learns from millions of examples." It translates "whole sentences at a time, rather than pieces. Google Translate supports over one hundred languages. The network encodes the "semantics of the sentence rather than simply memorizing phrase-to-phrase translations". GT uses English as an intermediate between most language pairs. </p>


  </body>
</html>
